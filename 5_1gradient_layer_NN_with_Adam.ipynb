{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Single-layer Neural Network with Pattern images based on Lengyel-Epstein model\n",
    "- X : imges, Z = W * gradient(X) + b\n",
    "- optimizer : Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import math\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset(144)\n",
    "x_orig = []\n",
    "y_orig = np.zeros((1,48))\n",
    "for i in range(1,145):\n",
    "    if i <= 48 :\n",
    "        folder = 0\n",
    "    elif i <=96 :\n",
    "        folder = 1\n",
    "    else:\n",
    "        folder = 2\n",
    "\n",
    "    img = Image.open('144/{0}/pattern_{1}.jpg'.format(folder,i)) \n",
    "    data = np.array(img)\n",
    "    x_orig.append(data)\n",
    "\n",
    "for i in range(1,3):\n",
    "    y_orig = np.append(y_orig, np.full((1, 48),i), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset(360)\n",
    "x_orig = []\n",
    "y_orig = np.zeros((1,120))\n",
    "for i in range(1,361):\n",
    "    if i <= 120 :\n",
    "        folder = 0\n",
    "    elif i <=240 :\n",
    "        folder = 1\n",
    "    else:\n",
    "        folder = 2\n",
    "\n",
    "    img = Image.open('360/{0}/pattern_{1}.jpg'.format(folder,i)) \n",
    "    data = np.array(img)\n",
    "    x_orig.append(data)\n",
    "\n",
    "for i in range(1,3):\n",
    "    y_orig = np.append(y_orig, np.full((1, 120),i), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset(720)\n",
    "x_orig = []\n",
    "y_orig = np.zeros((1,240))\n",
    "for i in range(1,721):\n",
    "    if i <= 240 :\n",
    "        folder = 0\n",
    "    elif i <=480 :\n",
    "        folder = 1\n",
    "    else:\n",
    "        folder = 2\n",
    "\n",
    "    img = Image.open('720/{0}/pattern_{1}.jpg'.format(folder,i)) \n",
    "    data = np.array(img)\n",
    "    x_orig.append(data)\n",
    "\n",
    "for i in range(1,3):\n",
    "    y_orig = np.append(y_orig, np.full((1, 240),i), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 64, 64)\n",
      "(1, 1440)\n"
     ]
    }
   ],
   "source": [
    "x_orig = np.array(x_orig)\n",
    "print(x_orig.shape)\n",
    "print(y_orig.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 64, 64)\n",
      "(1, 1440)\n"
     ]
    }
   ],
   "source": [
    "# Random shuffle\n",
    "s = np.arange(x_orig.shape[0])\n",
    "np.random.shuffle(s)\n",
    "\n",
    "x_shuffle = x_orig[s,:]\n",
    "y_shuffle = y_orig[:,s]\n",
    "\n",
    "print(x_shuffle.shape)\n",
    "print(y_shuffle.shape)\n",
    "# y_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test datasets\n",
    "x_train_orig, x_test_orig, y_train_orig, y_test_orig = train_test_split(x_shuffle,y_shuffle.T, \n",
    "                                                                        test_size=0.3,  shuffle=True, random_state=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 64, 64)\n",
      "(1008, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_orig.shape)\n",
    "print (y_train_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1008\n",
      "number of test examples = 432\n",
      "x_train shape: (4096, 1008)\n",
      "y_train shape: (3, 1008)\n",
      "x_test shape: (4096, 432)\n",
      "y_test shape: (3, 432)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Flatten the training and test images\n",
    "x_train_flatten = x_train_orig.reshape(x_train_orig.shape[0], -1).T\n",
    "x_test_flatten = x_test_orig.reshape(x_test_orig.shape[0], -1).T\n",
    "\n",
    "# Normalize image vectors\n",
    "x_train = x_train_flatten/255.\n",
    "x_test = x_test_flatten/255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "enc = OneHotEncoder()\n",
    "y1 = y_train_orig.reshape(-1,1)\n",
    "enc.fit(y1)\n",
    "y_train = enc.transform(y1).toarray()\n",
    "y_train = y_train.T\n",
    "\n",
    "y2 = y_test_orig.reshape(-1,1)\n",
    "enc.fit(y2)\n",
    "y_test = enc.transform(y2).toarray()\n",
    "y_test = y_test.T\n",
    "\n",
    "# Explore dataset \n",
    "print (\"number of training examples = \" + str(x_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(x_test.shape[1]))\n",
    "print (\"x_train shape: \" + str(x_train.shape))\n",
    "print (\"y_train shape: \" + str(y_train.shape))\n",
    "print (\"x_test shape: \" + str(x_test.shape))\n",
    "print (\"y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Define required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(nx, ny):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        nx -- size of the input layer (4096)\n",
    "        ny -- size of the output layer (3)\n",
    "    \n",
    "    Returns:\n",
    "        W -- weight matrix of shape (ny, nx)\n",
    "        b -- bias vector of shape (ny, 1)\n",
    "\n",
    "    \"\"\"   \n",
    "    np.random.seed(1)\n",
    "\n",
    "    W = np.random.randn(ny,nx)*0.01\n",
    "    b = np.zeros((ny,1))\n",
    "\n",
    "    assert(W.shape == (ny, nx))\n",
    "    assert(b.shape == (ny, 1))\n",
    "\n",
    "    \n",
    "    return W, b  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    # compute the softmax activation\n",
    "    \n",
    "    S = np.exp(Z + np.max(Z)) / np.sum(np.exp(Z + np.max(Z)), axis = 0)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classlabel(Z):\n",
    "    # probabilities back into class labels\n",
    "    y_hat = Z.argmax(axis=0)\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_vec(X):\n",
    "    g_X_r = np.gradient(X, axis = 1)\n",
    "    g_X_c = np.gradient(X, axis = 0)\n",
    "    g_X = g_X_r**2 + g_X_c**2\n",
    "    return g_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(W, b, X, Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "#     n = Y.shape[0]\n",
    "    \n",
    "    # Forward Propagation\n",
    "    Z = np.dot(W, gradient_vec(X))+ b\n",
    "    A = softmax(Z)     # compute activation\n",
    "    \n",
    "    cost = (-1/m) * np.sum(Y * np.log(A)) # compute cost (Cross_entropy)\n",
    "    \n",
    "    # Backward propagation\n",
    "    dW = (1/m) * (np.dot(gradient_vec(X),(A-Y).T)).T\n",
    "    db = (1/m) * (np.sum(A-Y))\n",
    "\n",
    "#     assert(dW.shape == W.shape)\n",
    "#     assert(db.dtype == float)\n",
    "#     cost = np.squeeze(cost)\n",
    "#     assert(cost.shape == (Y.shape[0],1))\n",
    "    \n",
    "    grads = {\"dW\": dW,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Single-Gradient Layer Neural Network with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, num_iterations, learning_rate, t, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, print_cost = False):\n",
    "\n",
    "    costs = []\n",
    "    W, b = initialize_parameters(4096,3)     \n",
    "    v_dW = np.zeros((W.shape[0],W.shape[1]))\n",
    "    v_db = np.zeros((b.shape[0],b.shape[1]))\n",
    "    s_dW = np.zeros((W.shape[0],W.shape[1]))\n",
    "    s_db = np.zeros((b.shape[0],b.shape[1]))\n",
    "\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        grads, cost = propagate(W, b, X, Y)\n",
    "\n",
    "        dW = grads[\"dW\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update parameters with adam\n",
    "        v_dW = beta1 * v_dW + (1-beta1) * dW\n",
    "        v_db = beta1 * v_db + (1-beta1) * db\n",
    "\n",
    "        # Compute bias-corrected first moment estimate\n",
    "        v_corrected_dW = v_dW / (1-beta1**t)\n",
    "        v_corrected_db = v_db / (1-beta1**t)\n",
    "        \n",
    "        # Moving average of the squared gradients\n",
    "        s_dW = beta2 * s_dW + (1-beta2) * dW ** 2\n",
    "        s_db = beta2 * s_db + (1-beta2) * db ** 2\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate.\n",
    "        s_corrected_dW = s_dW / (1-beta2**t)\n",
    "        s_corrected_db = s_db / (1-beta2**t)\n",
    "\n",
    "        # Update parameters\n",
    "        W = W - (learning_rate) * ((v_corrected_dW) / (s_corrected_dW **(1/2) + epsilon))\n",
    "        b = b - (learning_rate) * ((v_corrected_db) / (s_corrected_db ** (1/2) + epsilon))\n",
    "\n",
    "        # Record the costs for plotting\n",
    "        if i % 200 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 200 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per 200)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    # Lets save the trainded parameters in a variable\n",
    "    params = {\"W\": W,\n",
    "              \"b\": b}    \n",
    "    grads = {\"dW\": dW,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.098714\n",
      "Cost after iteration 200: 0.144494\n",
      "Cost after iteration 400: 0.086263\n",
      "Cost after iteration 600: 0.060650\n",
      "Cost after iteration 800: 0.045646\n",
      "Cost after iteration 1000: 0.035805\n",
      "Cost after iteration 1200: 0.028889\n",
      "Cost after iteration 1400: 0.023790\n",
      "Cost after iteration 1600: 0.019897\n",
      "Cost after iteration 1800: 0.016844\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3hcd33n8fdHo4stySPHtmJbshM7iUNiaUNDTYBl26aF5gKF9MIl2VIoZZvCNkALu2xou8DSsg8tdCksUJqmXMu1gbJuGkigBdJyjcMlRHZCTK6Ob4rt2JZkXee7f5wjeaxIthzr+MzofF7PM4/mXOac70zi+cw5v3N+P0UEZmZWXA15F2BmZvlyEJiZFZyDwMys4BwEZmYF5yAwMys4B4GZWcE5CKxwJH1J0ivyrsOsVjgI7LSR9KCk5+ZdR0RcGREfy7sOAElfl/RfTsN+WiR9WNIhSbslveEE675H0k5JByR9UFJT1jVafhwEtqBIasy7hkm1VAvwNmADcDbwi8CbJF0xy7rXA5uAXuB84GnAn5yGGi0nDgKrCZJ+RdIPJT0u6VuSLqpadr2kn0o6LGmrpF+rWvbbkr6Z/oLdD7wtnffvkt6d/qJ9QNKVVa+Z+hU+h3XXS7o93fdXJX1A0t/P8h4ulbRD0v+QtBv4iKQzJN0sqT/d/s2S1qTrvwP4OeD9kgYkvT+df4Gkr0jaL+leSS+Zh4/45cCfRsSBiNgG/C3w27Os+wLgfRGxPyL6gfcBvzMPNViNchBY7iQ9Dfgw8HvAcuBvgM2SWtJVfkryhdkB/C/g7yWtrtrEM4D7gTOBd1TNuxdYAfwF8HeSNEsJx1v3U8D30rreBvzWCd7OKmAZyS/va0n+jX0knT4LOAK8HyAi/hj4N+C6iGiPiOsktQFfSfd7JnAN8EFJPTPtLD1t8/gsj7vSdc4AuoAfVb30R8CM2wSUPqqn10jqOMF7tzrlILBa8LvA30TEdyNiIj1/PwI8EyAi/iEidkZEJSI+C9wHXFL1+p0R8X8jYjwijqTzHoqIv42ICeBjwGpg5Sz7n3FdSWcBTwfeEhGjEfHvwOYTvJcK8NaIGImIIxGxLyI+HxFDEXGYJKh+4Tiv/xXgwYj4SPp+vg98HnjRTCtHxH+NiKWzPCaPqtrTvwerXnoQWDJLDV8CXi+pU9Iq4HXp/NYTvHerU7V0DtOK62zgFZJeWzWvmeRXLJJeDrwBWJcuayf59T7pkRm2uXvySUQMpT/w22dY73jrrgD2R8TQtH2tPc576Y+I4ckJSa3Ae4ArgDPS2UskldLgme5s4BmSHq+a1wh84jj7PJGB9G8ZGK56fniW9d8BLAV+SBLIfwtcDOw9hRqshvmIwGrBI8A7pv2abY2IT0s6m+SL6DpgeUQsBe7m2FMXWXWhuwtYln6ZTzpeCMxUyxuBpwDPiIgy8PPpfM2y/iPAN6Z9Fu0R8ZqZdibpQ2n7wkyPPoCIOJC+l6dWvfSpQN+MbyA5krkuIroj4hxgH3DnLMFlC4CDwE63JkmLqh6NJF/0r5b0DCXaJD1f0hKgjeTLsh9A0itJrmbJXEQ8BGwhaYBulvQskobUk7GEpF3gcUnLgLdOW74HOKdq+mbgfEm/JakpfTxd0oWz1PjqNChmelS3AXwc+JO08foCktNxH51pm5K6JXWl/y2eCfzPGeq2BcRBYKfbLSRfjJOPt0XEFpIvpvcDB4DtpFe0RMRW4C+Bb5N8af4H4Junsd7fBJ5F8qv4z4DPkpwumau/AhYDjwHfAb48bfl7gRelVxS9L21HuAy4GthJctrqz4EWTs1bSRrdHwK+AbwrIr4MIOms9AjirHTdc4FvAYMkbSbXR8Rtp7h/q2HywDRmcyfps8A9EeFfyLZg+IjA7DjS0zLnSmpQcgPWVcAX867LbD75qiGz41sFfIHkPoIdwGsi4gf5lmQ2v3xqyMys4HxqyMys4Oru1NCKFSti3bp1eZdhZlZX7rzzzscionOmZXUXBOvWrWPLli15l2FmVlckPTTbMp8aMjMrOAeBmVnBOQjMzArOQWBmVnAOAjOzgnMQmJkVnIPAzKzgChMEWx7czzu/dA/uUsPM7FiFCYK+nYf40Dd+yp5DJ9OVvJnZwleYIOjpKgNw96MHT7CmmVmxFCYILlxdRkqODMzM7KjCBEFbSyPnrGjj7p0+IjAzq1aYIADo6eqgz6eGzMyOUagg6O0us/PgMPsHR/MuxcysZhQrCLo6AOjz6SEzsymFCoKNU1cOucHYzGxSoYJgaWsza85Y7CMCM7MqhQoCSE4P+RJSM7OjChcEPV1lHnhskMPDY3mXYmZWEwoXBL3dSYPxtl2Hc67EzKw2FC4I3NWEmdmxChcEZ5YX0bmkxXcYm5mlChcEAL1dZba6wdjMDMgwCCR9WNJeSXfPslyS3idpu6S7JD0tq1qm6+nq4L69AwyPTZyuXZqZ1awsjwg+ClxxnOVXAhvSx7XAX2dYyzF6u8tMVIJ7drvB2MwssyCIiNuB/cdZ5Srg45H4DrBU0uqs6qnW464mzMym5NlG0A08UjW9I533BJKulbRF0pb+/v5T3vGaMxbTsbjJXU2YmZFvEGiGeTMOKBwRN0TEpojY1NnZeeo7lujpKvuIwMyMfINgB7C2anoNsPN07by3u4N7dh9mbKJyunZpZlaT8gyCzcDL06uHngkcjIhdp2vnPV1lRscrbN87cLp2aWZWkxqz2rCkTwOXAisk7QDeCjQBRMSHgFuA5wHbgSHglVnVMpPJBuO7Hz3IhavLp3PXZmY1JbMgiIhrTrA8gN/Pav8nsn5FG63NJfp2HuLFeRVhZlYDCnlnMUCpQVy42g3GZmaFDQI42tVEpTLjxUpmZoVQ6CDo6e5gcHSCB/cN5l2KmVluih0Ek11SuwM6MyuwQgfBhjOX0FxqcDuBmRVaoYOgubGBp6xaQp+7mjCzAit0EEByeujunQdJrmY1MyseB0F3B48PjbHz4HDepZiZ5aLwQdDrMYzNrOAKHwQXrCrTIOhzEJhZQRU+CBY3lzjvzHb6fAmpmRVU4YMAoLerg7t9CamZFZSDANjYVWbPoRH6D4/kXYqZ2WnnICAZpAY8hrGZFZODgOSIAHA7gZkVkoMAKC9q4uzlrb6E1MwKyUGQ6u3q8BGBmRWSgyC1savMw/uHODg0lncpZmanlYMgNdVgvMunh8ysWBwEqcmxCbb69JCZFYyDILWivYVV5UVuMDazwnEQVOntLnu0MjMrHAdBlZ6uDu7vH2BodDzvUszMThsHQZWerjKVgG27DuddipnZaeMgqOKuJsysiBwEVVZ3LGJZW7PHMDazQnEQVJE0NYaxmVlROAim6enq4Cd7DjM6Xsm7FDOz0yLTIJB0haR7JW2XdP0My8+S9DVJP5B0l6TnZVnPXPR2lxmbCH6yxw3GZlYMmQWBpBLwAeBKYCNwjaSN01b7E+BzEXExcDXwwazqmaueLjcYm1mxZHlEcAmwPSLuj4hR4DPAVdPWCaCcPu8AdmZYz5ycvayV9pZG90RqZoWRZRB0A49UTe9I51V7G/AySTuAW4DXzrQhSddK2iJpS39/fxa1TmloEBu7yu5qwswKI8sg0AzzYtr0NcBHI2IN8DzgE5KeUFNE3BARmyJiU2dnZwalHqunq8y2XYeZqEwv18xs4ckyCHYAa6um1/DEUz+vAj4HEBHfBhYBKzKsaU56uzo4MjbBA48N5F2KmVnmsgyCO4ANktZLaiZpDN48bZ2HgecASLqQJAiyPfczB5N3GN/tG8vMrAAyC4KIGAeuA24FtpFcHdQn6e2SXpiu9kbgdyX9CPg08NsRkfv5mHM722hpbHA7gZkVQmOWG4+IW0gagavnvaXq+Vbg2VnW8GQ0lhq4YHXZVw6ZWSH4zuJZ9KZdTdTAAYqZWaYcBLPo6erg8PA4j+w/kncpZmaZchDMorc7uc/Ndxib2ULnIJjF+SuX0Ngg90RqZgueg2AWi5pKnHdmuy8hNbMFz0FwHL3dHfS5wdjMFjgHwXH0dpV5bGCUvYdH8i7FzCwzDoLj6Jm6w9jtBGa2cDkIjuPC1WUkfGOZmS1oDoLjaG9pZP2KNh8RmNmC5iA4gZ6uDh8RmNmC5iA4gd6uMo8+foQDg6N5l2JmlgkHwQkcHcPYRwVmtjA5CE6gpyvpasJ3GJvZQuUgOIEz2prpXrrYRwRmtmA5COagp6tMn68cMrMFykEwB73dHTywb5CBkfG8SzEzm3cOgjno7S4TAdt2+fSQmS08DoI5mLxyyDeWmdlC5CCYgzOXtLCivcUNxma2IDkI5kASvd1lHxGY2YLkIJijnq4y9+0dYHhsIu9SzMzmlYNgjnq7OpioBD/ZczjvUszM5pWDYI56p8YmcDuBmS0sDoI5WnPGYsqLGt3VhJktOA6COZLkLqnNbEFyEJyE3u4y23YdYmyikncpZmbzJtMgkHSFpHslbZd0/SzrvETSVkl9kj6VZT2nqqerg9HxCj/tH8i7FDOzedOY1YYllYAPAL8M7ADukLQ5IrZWrbMBeDPw7Ig4IOnMrOqZD73dSZfUfY8e4oJV5ZyrMTObH1keEVwCbI+I+yNiFPgMcNW0dX4X+EBEHACIiL0Z1nPK1q9oZ3FTyQ3GZragzCkIJL14LvOm6QYeqZrekc6rdj5wvqRvSvqOpCtm2f+1krZI2tLf3z+XkjNRahAXrl5Cny8hNbMFZK5HBG+e47xqmmFeTJtuBDYAlwLXADdKWvqEF0XcEBGbImJTZ2fnHMrNTm93B1t3HaJSmf5WzMzq03HbCCRdCTwP6Jb0vqpFZeBEnfPvANZWTa8Bds6wznciYgx4QNK9JMFwxxxqz0VvVwcf//ZDPLR/iPUr2vIux8zslJ3oiGAnsAUYBu6semwGLj/Ba+8ANkhaL6kZuDp9XbUvAr8IIGkFyami+0/mDZxuGyfHMHYHdGa2QBz3iCAifgT8SNKn0l/tSDoDWDvZwHuc145Lug64FSgBH46IPklvB7ZExOZ02WWStgITwH+PiH2n/rayc/7KJTSVRN/OQ7zgqV15l2NmdsrmevnoVyS9MF3/h0C/pG9ExBuO96KIuAW4Zdq8t1Q9D+AN6aMuNDc28JRVS+jzlUNmtkDMtbG4IyIOAb8OfCQifhZ4bnZl1bae1R3c/ehBkhwzM6tvcw2CRkmrgZcAN2dYT13o7S5zYGiMXQeH8y7FzOyUzTUI3k5yPv+nEXGHpHOA+7Irq7b1dHsMYzNbOOYUBBHxDxFxUUS8Jp2+PyJ+I9vSateFq8o0CO52T6RmtgDM9c7iNZL+UdJeSXskfV7SmqyLq1WLm0uc29nOVjcYm9kCMNdTQx8huQegi6SbiH9K5xVWT1fZo5WZ2YIw1yDojIiPRMR4+vgokG9fDznr7e5g96FhHhsYybsUM7NTMtcgeEzSyySV0sfLgJq+8StrPV1Jg7FHLDOzejfXIPgdkktHdwO7gBcBr8yqqHrgribMbKGY653Ffwq8YrJbCUnLgHeTBEQhdSxu4qxlrWz1EYGZ1bm5HhFcVN23UETsBy7OpqT60dtd9iA1Zlb35hoEDWlnc8DUEUFmw1zWi56uDh7aN8Sh4bG8SzEze9Lm+mX+l8C3JN1EMrjMS4B3ZFZVnehJ2wm27jzEM89ZnnM1ZmZPzlzvLP448BvAHqAf+PWI+ESWhdWDySuH3GBsZvVszqd3ImIrsDXDWupO55IWVpZbfAmpmdW1ubYR2Cx6uzo8NoGZ1TUHwSnq6e5g+94BjoxO5F2KmdmT4iA4RT1dZSoB23b79JCZ1ScHwSnq7XZXE2ZW3xwEp6irYxFntDbR5yuHzKxOOQhOkSR6ujp8h7GZ1S0HwTzo6S7zk90DjI5X8i7FzOykOQjmQW9XB6MTFe7bezjvUszMTpqDYB5MdjXR5xHLzKwOOQjmwbrlbbQ1l3xjmZnVJQfBPGhomGww9hGBmdUfB8E82dhVZuvOQ0xUIu9SzMxOioNgnvR2d3BkbIIHHhvMuxQzs5OSaRBIukLSvZK2S7r+OOu9SFJI2pRlPVnq7U4bjN1OYGZ1JrMgkFQCPgBcCWwErpG0cYb1lgCvA76bVS2nw7md7TQ3NnhsAjOrO1keEVwCbI+I+yNiFPgMcNUM6/0p8BfAcIa1ZK6p1MCFq5a4zyEzqztZBkE38EjV9I503hRJFwNrI+Lm421I0rWStkja0t/fP/+VzpOe7g7ufvQgEW4wNrP6kWUQaIZ5U9+QkhqA9wBvPNGGIuKGiNgUEZs6OzvnscT51dNV5tDwODsOHMm7FDOzOcsyCHYAa6um1wA7q6aXAL3A1yU9CDwT2FzXDcZdk11Su53AzOpHlkFwB7BB0npJzcDVwObJhRFxMCJWRMS6iFgHfAd4YURsybCmTD1l1RJKDeJudzVhZnUksyCIiHHgOuBWYBvwuYjok/R2SS/Mar95WtRUYsOZ7T4iMLO60pjlxiPiFuCWafPeMsu6l2ZZy+nS09XB7ffVboO2mdl0vrN4nvV0lek/PMLeQ3V9NayZFYiDYJ55DGMzqzcOgnm2MR2bwHcYm1m9cBDMs/aWRtavaPMYxmZWNxwEGejpKvvUkJnVDQdBBnq7O9hx4AiPD43mXYqZ2Qk5CDIwNYaxjwrMrA44CDLQ464mzKyOOAgysKytme6li93VhJnVBQdBRjZ2lX3lkJnVBQdBRnq7OnjgsUEGR8bzLsXM7LgcBBnp7S4TAdt2+fSQmdU2B0FGJhuMfYexmdU6B0FGVpZbWNHe7EtIzazmOQgyIomerg7udhCYWY1zEGSop6vMfXsOMzI+kXcpZmazchBkqLe7g/FK8JPdA3mXYmY2KwdBhiYHs/f9BGZWyxwEGVq7bDFLFjX6yiEzq2kOggwlDcbuktrMapuDIGO9XR1s23WI8YlK3qWYmc3IQZCxnu4yI+MV7n9sMO9SzMxm5CDIWK/vMDazGucgyNg5ne0sampwl9RmVrMcBBkrNYgLV5c9SI2Z1SwHwWnQ29XB1p2HqFQi71LMzJ7AQXAa9HaXOTwyzsP7h/IuxczsCTINAklXSLpX0nZJ18+w/A2Stkq6S9K/SDo7y3rycnQMY7cTmFntySwIJJWADwBXAhuBayRtnLbaD4BNEXERcBPwF1nVk6cNK9tpKsldTZhZTcryiOASYHtE3B8Ro8BngKuqV4iIr0XE5PmS7wBrMqwnNy2NJTacucSXkJpZTcoyCLqBR6qmd6TzZvMq4EszLZB0raQtkrb09/fPY4mnT293ma07DxHhBmMzqy1ZBoFmmDfjt6CklwGbgHfNtDwiboiITRGxqbOzcx5LPH16uzvYNzjK7kPDeZdiZnaMLINgB7C2anoNsHP6SpKeC/wx8MKIGMmwnlz1dJUBfGOZmdWcLIPgDmCDpPWSmoGrgc3VK0i6GPgbkhDYm2EtubtwdRkJ31hmZjUnsyCIiHHgOuBWYBvwuYjok/R2SS9MV3sX0A78g6QfSto8y+bqXmtzI+d2tvuIwMxqTmOWG4+IW4Bbps17S9Xz52a5/1rT01Xmew/sz7sMM7Nj+M7i06i3q4NdB4fZN7Bgm0LMrA45CE6jnu6kwdh3GJtZLXEQnEY9qz2YvZnVHgfBadTR2sTaZYt9RGBmNcVBcJpdvPYMbvnxLl7yoW9z47/dzyPukdTMcqZ66/Jg06ZNsWXLlrzLeNL2DYzw8W8/xK19u7ln92EALli1hMt7VnF5zyouXL0Eaaabss3MnjxJd0bEphmXOQjy8/C+IW7bupvb+vZwx0P7iYC1yxZz2cZVXLZxJZvWLaPU4FAws1PnIKgDjw2M8NWte7ht6x7+/b7HGJ2osKytmedeeCaX96zi2eetYFFTKe8yzaxOOQjqzMDION+4t59b+3bztXv2cnhknNbmEpc+pZPLe1Zx6VPOpGNxU95lmlkdOV4QZHpnsT057S2NPP+i1Tz/otWMjlf49v37uLVvN1/ZuodbfrybxgbxrHOXc1lPcgppZXlR3iWbWR3zEUEdqVSCHzzy+FS7wgOPDQLwM2uXpo3NKzmnsz3nKs2sFvnU0AIUEWzfO8Ctfbu5tW8PP05HPzvvzHYu71nJZRtXcdGaDl+BZGaAg6AQdj5+hNv6dnPb1j1894H9TFSCVeVFXNazkst7VnHJ+mU0lXzbiFlROQgK5sDgKP96z15u7dvN7ff1MzxWoWNxE8+54Ewu61nJz5/fSWuzm4fMisRBUGBHRie4/b5+buvbw7/cs4fHh8ZoaWzg5zZ08sxzlnHWslbOXt7GWctaWdzsy1PNFipfNVRgi5tLU3ctj09U+N6D+7mtbw+39e3mq9v2HLPuynILZy9v4+xlraxb0ZaGRBIUvlzVbOHyEUGBPT40ykP7hnho/xAPPTaY/N03yEP7hth7+NgxE5a2Nh0NieWtnLW8LQ2JVjrbW9wobVbjfERgM1ra2szS1maeunbpE5YNjY7z8P6hJCjScHho3xA/eOQAN9+1k0rV74fW5tLU0cO65W2ctbyVs5clQdG1dLG7yTCrcQ4Cm1FrcyMXrCpzwaryE5aNjld49PEjxwTEw/sH+Wn/IF+7t5/R8crUuk0lsfaMVs6aDImq001rly2mpdHtEmZ5cxDYSWtubGD9ijbWr2h7wrJKJdh9aHgqHB7cN8TD+4Z4cN8gdz54gMMj41PrSrC6vIgzy4tY3tbMsmmP5e3NnNHazPK2Fpa1N9PWXPIpKLMMOAhsXjU0iK6li+lauphnnbv8mGURwYGhMR7cNzgVDg/vG6J/YITdh4bZuusQ+wZHjzmiqNbc2MCy1qMhsaxtMiiaWdae/D2jdXJZC0sXN9Hg01JmJ+QgsNNG0tSv/aeddcaM60QEQ6MT7B8cZd/gKPsHR9g/OMb+wZFkemCUA0PJsof3D7F/YPSYo4xqDUraQaaOMlqPBsb0o49lbc0sWdREa1PJ4WGF4yCwmiKJtpZG2loaWbusdU6vGRmf4PGhMfYNjKYBMsKBwdGqMEkeP+0f4I4HkyCpzHKxnATtzcn+2xclf5e0NNKe1rRkUSNtLSXaW5poX9RIe/q8raXEknTe5PNFTQ0+lWV1wUFgda+lscTKcmnOvbBOVIKDR8amAmLyqGNgZIyB4XEGRiYYGBljcGSCwyPjDAyP0X94hIGR8anHxGxJUqXUINqaSyxZ1JSGRyPti5rS8KgKmTRw2tPH4qYSLU0lFjeVWNTUwOLmEosaSyxuLtHS6HCx+ecgsMIpNRw9RfVkRATDY5WpUBgcGefwcNXz9O/A8NHgGBgeZ3B0nENHxtj5+JGjy0fHOdlbeRY1NaQhUaoKjYap6UWTy5obpgJk0dT8Y1+7aIawWdRYoqWpwaFTIA4Cs5MkicXNyZdm55KWU9pWpRIcGZs4JjCGxyYYHq9wZHSCkfEJjoxOcGRsguGxCkfGJhgZm5ye4MjYsesdGh7jyGiy7nDVenM4gJlRU0k0lxpobqx6lBpoaSxNTbek86qXV6/fMm1ZS1Pp+OtM20ZTQwONJdFUaqCp1OD7UjLgIDDLUUPD0TaRlRntIyIYnagcDYfRCYbT4JicNxkak4EzPDbB6HiF0YlK8ne8wsj4sfNG0vkDI+NT61SvPzpeYSSdnk8NgsZSA00NoqmxgcaGBppLorGUBEZz+jeZXx0iybymxuS11eHSlL6+qSGZ15jOa5p8fUMSQJPbLTWIxgZRmras1PDE6caGtLaG2afzPvJyEJgtcJJoaSzR0ljKpc+oySCaKSxGZgiPY5ZPVBifqDA+kWxjfCIYr1Smno9NVBibCMYnKsnzyuTzyWXJdgZHJxgbrzBeOXZbk+uMV45uKw+lqlA4Xni8/jkbeMFTu+Z9/5kGgaQrgPcCJeDGiHjntOUtwMeBnwX2AS+NiAezrMnMTq/qIKp1EcF4JZKQqFTS8JiclzyfSJePV46dnqgkr5mYiKPz0+CZqEzOS8LmeNPjU9s/dnqiEixtzSbIMwsCSSXgA8AvAzuAOyRtjoitVau9CjgQEedJuhr4c+ClWdVkZnY8ktJTQrCY2g+u+ZLlkFWXANsj4v6IGAU+A1w1bZ2rgI+lz28CnqO8T5aZmRVMlkHQDTxSNb0jnTfjOhExDhwElk9bB0nXStoiaUt/f39G5ZqZFVOWQTDTL/vpLTFzWYeIuCEiNkXEps7OznkpzszMElkGwQ5gbdX0GmDnbOtIagQ6gP0Z1mRmZtNkGQR3ABskrZfUDFwNbJ62zmbgFenzFwH/GvU2ZJqZWZ3L7KqhiBiXdB1wK8nlox+OiD5Jbwe2RMRm4O+AT0jaTnIkcHVW9ZiZ2cwyvY8gIm4Bbpk27y1Vz4eBF2dZg5mZHV+Wp4bMzKwOqN5OyUvqBx56ki9fATw2j+XUO38ex/LncZQ/i2MthM/j7IiY8bLLuguCUyFpS0RsyruOWuHP41j+PI7yZ3Gshf55+NSQmVnBOQjMzAquaEFwQ94F1Bh/Hsfy53GUP4tjLejPo1BtBGZm9kRFOyIwM7NpHARmZgVXmCCQdIWkeyVtl3R93vXkRdJaSV+TtE1Sn6TX511TLZBUkvQDSTfnXUveJC2VdJOke9L/T56Vd015kfSH6b+TuyV9WtKivGvKQiGCoGq0tCuBjcA1kjbmW1VuxoE3RsSFwDOB3y/wZ1Ht9cC2vIuoEe8FvhwRFwBPpaCfi6Ru4HXApojoJekzbUH2h1aIIGBuo6UVQkTsiojvp88Pk/wjnz5gUKFIWgM8H7gx71ryJqkM/DxJh5BExGhEPJ5vVblqBBan3eS38sSu9BeEogTBXEZLKxxJ64CLge/mW0nu/gp4E1DJu5AacA7QD3wkPVV2o6S2vIvKQ0Q8CrwbeBjYBRyMiNvyrSobRQmCOY2EViSS2oHPA38QEYfyricvkn4F2BsRd+ZdS41oBJ4G/HVEXAwMAoVsU5N0BsmZg/VAF9Am6WX5VpWNogTBXEZLKwxJTSQh8MmI+ELe9eTs2cALJT1IcsrwlyT9fb4l5WoHsCMiJo8SbyIJhiJ6LvBARPRHxBjwBeA/5lxTJooSBHMZLa0QJInk/O+2iPg/edeTt4h4c0SsiYh1JP9f/F4OSMoAAASoSURBVGtELMhffXMREbuBRyQ9JZ31HGBrjiXl6WHgmZJa0383z2GBNpxnOjBNrZhttLScy8rLs4HfAn4s6YfpvD9KBxEyA3gt8Mn0R9P9wCtzricXEfFdSTcB3ye52u4HLNCuJtzFhJlZwRXl1JCZmc3CQWBmVnAOAjOzgnMQmJkVnIPAzKzgHARWUyR9K/27TtJ/nudt/9FM+8qKpF+V9JYMttsq6Z/T3kH7JL2zalmLpM+mvex+N+1GZHLZm9P590q6PJ3XLOn2tC8dKygHgdWUiJi8c3MdcFJBkPYyezzHBEHVvrLyJuCDp7qRWd7Xu9PeQS8Gni3pynT+q4ADEXEe8B7gz9NtbCS5Ya4HuAL4oKRS2gnjvwAvPdU6rX45CKymSBpIn74T+DlJP0z7hC9JepekOyTdJen30vUvTcdX+BTw43TeFyXdmf5avjad906SXiR/KOmT1ftS4l1pn/M/lvTSqm1/vapv/k+md5gi6Z2Stqa1vHuG93E+MBIRj6XTH5X0IUn/JuknaR9Hk+MgzOl9TYqIoYj4Wvp8lOSGpzXp4quAj6XPbwKek9Z8FfCZiBiJiAeA7SS98gJ8EfjNk/+vZQuFDwetVl0P/LeImPzCvJak98enS2oBvilpsifIS4De9AsO4HciYr+kxcAdkj4fEddLui4ifmaGff068DMkfe+vSF9ze7rsYpJf0TuBb5L8+t4K/BpwQUSEpKUzbPPZJF/Q1dYBvwCcC3xN0nnAy0/ifT1Buu8XkIwhAFU97aZ31B8Elqfzv1P10uoeeO8Gnj7bPmzhcxBYvbgMuEjSi9LpDmADMAp8b9qX5esk/Vr6fG263r7jbPs/AZ+OiAlgj6RvkHwxHkq3vQMg7ZJjHckX6jBwo6R/BmYa1Ww1SXfO1T4XERXgPkn3Axec5Ps6Rnpe/9PA+yLi/snZM6wax5lPRExIGpW0JB2jwgrGQWD1QsBrI+LWY2ZKl5J0lVw9/VzgWRExJOnrwImGF5zpS3LSSNXzCaAx/aV9CUknZFcD1wG/NO11R0i+1KtN789l8gv6hO9rFjcA90XEX1XNm+xpd0caFB3Afk7cA28LSbhZAbmNwGrVYWBJ1fStwGuUdKGNpPM184ApHSSNpUOSLiAZjnPS2OTrp7kdeGl6vr6TZISu781WmJKxHDrSjvr+gOS00nTbgPOmzXuxpAZJ55IMAHPvSbyv6TX8Wfpe/2Daos3AK9LnLyLpTTXS+VenVxWtJznq+F66reXAZFfLVkA+IrBadRcwLulHwEdJzoGvA76fNn72A786w+u+DLxa0l0kX7TV58VvAO6S9P2IqG4c/UfgWcCPSH6lvykidqdBMpMlwP9TMpC5gD+cYZ3bgb+UpDjas+O9wDeAlcCrI2JY0o1zfF9TlAyt+cfAPenrAN4fETeSdDH+CUnbSY4ErgaIiD5JnyPpUnoc+P30VBjALwLufbbA3PuoWUYkvRf4p4j4qqSPAjdHxE05l/UEkr4AvDki7s27FsuHTw2ZZed/kwx4XrOUjDnwRYdAsfmIwMys4HxEYGZWcA4CM7OCcxCYmRWcg8DMrOAcBGZmBff/ARyavhvbz+xjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[  2.50934456   6.17733485   5.44041504 ...   8.31645126   9.64939476\n",
      "   10.38698927]\n",
      " [-11.16880787  -8.58595244  -0.63684861 ...  -6.69644835  -3.67368722\n",
      "   -2.64501852]\n",
      " [ 12.55292978   6.02316126  -1.59372459 ...   1.69422986  -2.88732411\n",
      "   -4.78004141]]\n",
      "b = [[-9.02304216e-08]\n",
      " [-9.02304216e-08]\n",
      " [-9.02304216e-08]]\n",
      "dw = [[ 7.93297397e-08 -1.28129805e-06 -1.39478207e-06 ... -2.30007579e-06\n",
      "  -2.02467796e-06 -2.30687442e-06]\n",
      " [ 4.36521465e-06  3.22673995e-06  1.98436253e-07 ...  2.63698604e-06\n",
      "   1.23883448e-06  1.38688339e-06]\n",
      " [-4.44454439e-06 -1.94544190e-06  1.19634581e-06 ... -3.36910253e-07\n",
      "   7.85843477e-07  9.19991034e-07]]\n",
      "db = 1.5419764230904951e-18\n"
     ]
    }
   ],
   "source": [
    "params, grads, costs = optimize(x_train, y_train, num_iterations=2000, learning_rate=0.9,\n",
    "                                t=2, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, print_cost = True)\n",
    "\n",
    "print (\"W = \" + str(params[\"W\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dW\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, b, X) :\n",
    "    '''\n",
    "    Predict the label(0,1,2) using argmax\n",
    "    \n",
    "    Arguments:\n",
    "    X : data of size (num_px * num_px, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    y_prediction : predictions (0/1/2) for the examples(my_image)\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Compute \"A\" predicting the probabilities\n",
    "    Z = np.dot(W, gradient_vec(X))+ b\n",
    "    A = softmax(Z) \n",
    "\n",
    "    # Convert probabilities A to actual predictions\n",
    "    y_prediction = A.argmax(axis=0)\n",
    "    \n",
    "#     assert(y_prediction.shape == (1, m))\n",
    "    \n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 ... 0 2 1]\n",
      "[0 2 0 2 0 2 1 1 1 1 1 1 1 2 1 1 2 0 2 0 2 2 2 1 2 1 1 1 0 0 2 0 2 0 2 0 1\n",
      " 1 0 2 1 2 1 0 0 1 0 1 1 1 2 1 0 1 2 1 2 0 2 0 2 1 2 2 0 0 2 2 2 1 1 0 2 0\n",
      " 0 2 0 0 2 1 0 2 2 0 2 0 2 0 0 0 2 1 1 2 2 0 0 0 1 1 0 1 2 2 0 1 2 2 2 2 0\n",
      " 0 0 2 2 1 1 2 1 2 1 2 1 2 2 0 0 0 1 0 1 2 2 0 2 0 1 2 1 0 1 1 1 1 0 0 1 2\n",
      " 1 0 1 2 0 0 1 1 1 0 0 2 1 0 0 1 2 1 2 2 1 0 2 1 1 0 2 0 2 2 2 0 0 2 2 2 0\n",
      " 1 1 0 1 0 1 2 2 1 0 2 0 1 0 1 1 0 0 0 2 2 1 2 1 0 2 2 2 0 2 0 1 2 1 0 1 1\n",
      " 1 1 1 0 1 0 1 0 1 0 2 2 2 1 2 1 2 2 2 0 0 2 1 2 0 1 0 0 0 0 0 1 1 0 0 2 0\n",
      " 1 2 1 0 1 0 2 0 0 1 0 2 0 2 0 2 2 2 2 1 1 1 0 1 1 0 1 1 0 1 0 2 1 2 1 1 1\n",
      " 1 2 0 2 1 2 0 1 0 2 0 0 1 0 2 0 2 0 0 1 0 1 0 2 2 1 1 1 2 2 1 1 1 2 1 0 2\n",
      " 2 1 1 1 1 1 1 1 1 0 2 1 1 2 0 1 0 2 0 0 0 2 1 1 1 2 0 1 0 1 0 0 2 2 0 1 0\n",
      " 1 1 0 2 1 0 1 1 1 1 0 2 0 1 0 0 2 2 0 2 2 1 1 1 2 0 2 1 0 1 0 1 2 0 2 0 2\n",
      " 1 1 1 0 0 1 2 1 2 2 0 2 1 0 2 2 1 0 0 2 0 1 1 1 1]\n",
      "train accuracy :  1.0\n",
      "test accuracy :  0.3449074074074074\n"
     ]
    }
   ],
   "source": [
    "# Predict test/train set\n",
    "W1 = params['W']\n",
    "b1 = params['b']\n",
    "y_prediction_train = predict(W1, b1, x_train)\n",
    "y_prediction_test = predict(W1, b1, x_test)\n",
    "print(y_prediction_train)\n",
    "print(y_prediction_test)\n",
    "# Print train/test Errors\n",
    "print(\"train accuracy : \", metrics.accuracy_score(y_prediction_train, y_train_orig))\n",
    "print(\"test accuracy : \", metrics.accuracy_score(y_prediction_test, y_test_orig))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
