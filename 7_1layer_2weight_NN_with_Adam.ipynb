{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Single-layer Neural Network with Pattern images based on Lengyel-Epstein model\n",
    "- X : imges, Z = W1 * gradient(X) + W2 * X + b\n",
    "- optimizer : Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import math\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset(144)\n",
    "x_orig = []\n",
    "y_orig = np.zeros((1,48))\n",
    "for i in range(1,145):\n",
    "    if i <= 48 :\n",
    "        folder = 0\n",
    "    elif i <=96 :\n",
    "        folder = 1\n",
    "    else:\n",
    "        folder = 2\n",
    "\n",
    "    img = Image.open('144/{0}/pattern_{1}.jpg'.format(folder,i)) \n",
    "    data = np.array(img)\n",
    "    x_orig.append(data)\n",
    "\n",
    "for i in range(1,3):\n",
    "    y_orig = np.append(y_orig, np.full((1, 48),i), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset(360)\n",
    "x_orig = []\n",
    "y_orig = np.zeros((1,120))\n",
    "for i in range(1,361):\n",
    "    if i <= 120 :\n",
    "        folder = 0\n",
    "    elif i <=240 :\n",
    "        folder = 1\n",
    "    else:\n",
    "        folder = 2\n",
    "\n",
    "    img = Image.open('360/{0}/pattern_{1}.jpg'.format(folder,i)) \n",
    "    data = np.array(img)\n",
    "    x_orig.append(data)\n",
    "\n",
    "for i in range(1,3):\n",
    "    y_orig = np.append(y_orig, np.full((1, 120),i), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset(720)\n",
    "x_orig = []\n",
    "y_orig = np.zeros((1,240))\n",
    "for i in range(1,721):\n",
    "    if i <= 240 :\n",
    "        folder = 0\n",
    "    elif i <=480 :\n",
    "        folder = 1\n",
    "    else:\n",
    "        folder = 2\n",
    "\n",
    "    img = Image.open('720/{0}/pattern_{1}.jpg'.format(folder,i)) \n",
    "    data = np.array(img)\n",
    "    x_orig.append(data)\n",
    "\n",
    "for i in range(1,3):\n",
    "    y_orig = np.append(y_orig, np.full((1, 240),i), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 64, 64)\n",
      "(1, 1440)\n"
     ]
    }
   ],
   "source": [
    "# Explore dataset\n",
    "x_orig = np.array(x_orig)\n",
    "print(x_orig.shape)\n",
    "print(y_orig.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 64, 64)\n",
      "(1, 1440)\n"
     ]
    }
   ],
   "source": [
    "# Random shuffle\n",
    "s = np.arange(x_orig.shape[0])\n",
    "np.random.shuffle(s)\n",
    "\n",
    "x_shuffle = x_orig[s,:]\n",
    "y_shuffle = y_orig[:,s]\n",
    "\n",
    "print(x_shuffle.shape)\n",
    "print(y_shuffle.shape)\n",
    "# y_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test datasets\n",
    "x_train_orig, x_test_orig, y_train_orig, y_test_orig = train_test_split(x_shuffle,y_shuffle.T, \n",
    "                                                                        test_size=0.3,  shuffle=True, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 64, 64)\n",
      "(1008, 1)\n",
      "[343]\n",
      "[332]\n",
      "[333]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_orig.shape)\n",
    "print (y_train_orig.shape)\n",
    "print(sum(y_train_orig==0))\n",
    "print(sum(y_train_orig==1))\n",
    "print(sum(y_train_orig==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1008\n",
      "number of test examples = 432\n",
      "x_train shape: (4096, 1008)\n",
      "y_train shape: (3, 1008)\n",
      "x_test shape: (4096, 432)\n",
      "y_test shape: (3, 432)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Flatten the training and test images\n",
    "x_train_flatten = x_train_orig.reshape(x_train_orig.shape[0], -1).T\n",
    "x_test_flatten = x_test_orig.reshape(x_test_orig.shape[0], -1).T\n",
    "\n",
    "# Normalize image vectors\n",
    "x_train = x_train_flatten/255.\n",
    "x_test = x_test_flatten/255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "enc = OneHotEncoder()\n",
    "y1 = y_train_orig.reshape(-1,1)\n",
    "enc.fit(y1)\n",
    "y_train = enc.transform(y1).toarray()\n",
    "y_train = y_train.T\n",
    "\n",
    "y2 = y_test_orig.reshape(-1,1)\n",
    "enc.fit(y2)\n",
    "y_test = enc.transform(y2).toarray()\n",
    "y_test = y_test.T\n",
    "\n",
    "# Explore dataset \n",
    "print (\"number of training examples = \" + str(x_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(x_test.shape[1]))\n",
    "print (\"x_train shape: \" + str(x_train.shape))\n",
    "print (\"y_train shape: \" + str(y_train.shape))\n",
    "print (\"x_test shape: \" + str(x_test.shape))\n",
    "print (\"y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Define required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(nx, ny):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        nx -- size of the input layer (4096)\n",
    "        ny -- size of the output layer (3)\n",
    "    \n",
    "    Returns:\n",
    "        W -- weight matrix of shape (ny, nx)\n",
    "        b -- bias vector of shape (ny, 1)\n",
    "\n",
    "    \"\"\"   \n",
    "    np.random.seed(1)\n",
    "\n",
    "    W1 = np.random.randn(ny,nx)*0.01\n",
    "    W2 = np.random.randn(ny,nx)*0.01\n",
    "    b = np.zeros((ny,1))\n",
    "\n",
    "    assert(W1.shape == (ny, nx))\n",
    "    assert(W2.shape == (ny, nx))\n",
    "    assert(b.shape == (ny, 1))\n",
    "\n",
    "    \n",
    "    return W1, W2, b  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    # compute the softmax activation\n",
    "    \n",
    "    S = np.exp(Z + np.max(Z)) / np.sum(np.exp(Z + np.max(Z)), axis = 0)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classlabel(Z):\n",
    "    # probabilities back into class labels\n",
    "    y_hat = Z.argmax(axis=0)\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_vec(X):\n",
    "    g_X_r = np.gradient(X, axis = 1)\n",
    "    g_X_c = np.gradient(X, axis = 0)\n",
    "    g_X = g_X_r**2 + g_X_c**2\n",
    "    return g_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 1008)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = gradient_vec(x_train)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(W1,W2, b, X, Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "#     n = Y.shape[0]\n",
    "    \n",
    "    # Forward Propagation\n",
    "    Z = np.dot(W1, gradient_vec(X))+ (np.dot(W2,X)+b)\n",
    "    A = softmax(Z)     # compute activation\n",
    "    \n",
    "    cost = (-1/m) * np.sum(Y * np.log(A))  # compute cost (Cross_entropy)\n",
    "    \n",
    "    # Backward propagation   \n",
    "    dW1 = (1/m) * (np.dot(gradient_vec(X),(A-Y).T)).T\n",
    "    dW2 = (1/m) * (np.dot(X,(A-Y).T)).T\n",
    "    db = (1/m) * (np.sum(A-Y))\n",
    "    \n",
    "#     assert(dW.shape == W.shape)\n",
    "#     assert(db.dtype == float)\n",
    "#     cost = np.squeeze(cost)\n",
    "#     assert(cost.shape == (Y.shape[0],1))\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"dW2\" : dW2,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Single-2weight Layer Neural Network with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, num_iterations, learning_rate, t, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, print_cost = False):\n",
    "\n",
    "    costs = []\n",
    "    W1, W2, b = initialize_parameters(4096,3)\n",
    "     # initialize with adam\n",
    "    v_dW1 = np.zeros((W1.shape[0],W1.shape[1]))\n",
    "    v_dW2 = np.zeros((W2.shape[0],W2.shape[1]))\n",
    "    v_db = np.zeros((b.shape[0],b.shape[1]))\n",
    "    \n",
    "    s_dW1 = np.zeros((W1.shape[0],W1.shape[1]))\n",
    "    s_dW2 = np.zeros((W2.shape[0],W2.shape[1]))\n",
    "    s_db = np.zeros((b.shape[0],b.shape[1]))\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        grads, cost = propagate(W1,W2, b, X, Y)\n",
    "\n",
    "        dW1 = grads[\"dW1\"]\n",
    "        dW2 = grads[\"dW2\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update parameters with adam\n",
    "        v_dW1 = beta1 * v_dW1 + (1-beta1) * dW1\n",
    "        v_dW2 = beta1 * v_dW2 + (1-beta1) * dW2\n",
    "        v_db = beta1 * v_db + (1-beta1) * db\n",
    "\n",
    "        # Compute bias-corrected first moment estimate\n",
    "        v_corrected_dW1 = v_dW1 / (1-beta1**t)\n",
    "        v_corrected_dW2 = v_dW2 / (1-beta1**t)\n",
    "        v_corrected_db = v_db / (1-beta1**t)\n",
    "        \n",
    "        # Moving average of the squared gradients\n",
    "        s_dW1 = beta2 * s_dW1 + (1-beta2) * dW1 ** 2\n",
    "        s_dW2 = beta2 * s_dW2 + (1-beta2) * dW2 ** 2\n",
    "        s_db = beta2 * s_db + (1-beta2) * db ** 2\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate.\n",
    "        s_corrected_dW1 = s_dW1 / (1-beta2**t)\n",
    "        s_corrected_dW2 = s_dW2 / (1-beta2**t)\n",
    "        s_corrected_db = s_db / (1-beta2**t)\n",
    "\n",
    "        # Update parameters\n",
    "        W1 = W1 - (learning_rate) * ((v_corrected_dW1) / (s_corrected_dW1 **(1/2) + epsilon))\n",
    "        W2 = W2 - (learning_rate) * ((v_corrected_dW2) / (s_corrected_dW2 **(1/2) + epsilon))\n",
    "        b = b - (learning_rate) * ((v_corrected_db) / (s_corrected_db ** (1/2) + epsilon))\n",
    "\n",
    "        # Record the costs for plotting\n",
    "        if i % 200 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 200 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per 200)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    # Lets save the trainded parameters in a variable\n",
    "    params = {\"W1\": W1,\n",
    "              \"W2\": W2,\n",
    "              \"b\": b}    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"dW2\":dW2,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.095678\n",
      "Cost after iteration 200: 12.664003\n",
      "Cost after iteration 400: 0.955016\n",
      "Cost after iteration 600: 0.377431\n",
      "Cost after iteration 800: 0.317457\n",
      "Cost after iteration 1000: 0.278037\n",
      "Cost after iteration 1200: 0.255944\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.81349117 -0.19220398 -0.7878607  ...  0.36504411  0.06861399\n",
      "  -0.34905584]\n",
      " [-0.06010139  0.05417729  0.62319032 ... -0.53762137 -0.38884774\n",
      "   0.24419687]\n",
      " [-0.67299846  0.29877986  0.32778676 ...  0.23710955  0.41579735\n",
      "   0.25098491]]\n",
      "W2 = [[-0.11023509  0.05416188  0.00475998 ...  0.03401764  0.04540081\n",
      "  -0.00026561]\n",
      " [ 0.06076452  0.00064384  0.02175257 ...  0.16270174  0.06790461\n",
      "   0.05669415]\n",
      " [ 0.14701128  0.03663742  0.04651135 ... -0.0654719  -0.03804284\n",
      "   0.02753162]]\n",
      "b = [[1.63724866e-12]\n",
      " [1.63724866e-12]\n",
      " [1.63724866e-12]]\n"
     ]
    }
   ],
   "source": [
    "params, grads, costs = optimize(x_train, y_train, num_iterations=1400, learning_rate=0.06,\n",
    "                                t=2, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-4, print_cost = True)\n",
    "\n",
    "print (\"W1 = \" + str(params[\"W1\"]))\n",
    "print (\"W2 = \" + str(params[\"W2\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W1,W2, b, X) :\n",
    "    '''\n",
    "    Predict the label(0,1,2) using argmax\n",
    "    \n",
    "    Arguments:\n",
    "    X : data of size (num_px * num_px, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    y_prediction : predictions (0/1/2) for the examples(my_image)\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Compute \"A\" predicting the probabilities\n",
    "    Z = np.dot(W1, gradient_vec(X))+ (np.dot(W2,X)+b)\n",
    "    A = softmax(Z)     # compute activation\n",
    "\n",
    "    # Convert probabilities A to actual predictions\n",
    "    y_prediction = A.argmax(axis=0)\n",
    "    \n",
    "#     assert(y_prediction.shape == (1, m))\n",
    "    \n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 0 2]\n",
      "[1 0 2 0 2 2 0 0 0 0 1 1 0 2 0 1 0 0 0 0 0 2 1 0 0 0 2 0 1 0 0 2 1 0 2 0 0\n",
      " 1 0 0 0 2 0 0 2 1 2 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 0 0 2 2 1 0 1 1 1\n",
      " 2 0 2 1 1 2 2 1 2 1 2 2 1 0 1 0 0 1 0 2 0 0 1 1 0 1 0 1 1 0 1 2 0 0 0 0 0\n",
      " 2 1 0 2 2 2 0 0 2 0 1 2 0 2 0 0 2 0 2 0 0 0 0 2 0 2 0 0 1 0 0 0 2 2 0 0 0\n",
      " 2 1 1 1 0 2 0 1 0 1 0 0 1 0 0 0 0 0 2 0 2 0 0 0 1 0 0 1 0 1 2 1 2 1 0 2 0\n",
      " 1 0 0 0 0 0 1 0 2 1 0 2 1 2 1 0 1 2 0 2 0 1 0 0 1 2 0 2 0 0 0 0 2 0 0 0 0\n",
      " 1 1 0 0 0 0 1 0 1 2 1 1 0 0 0 1 0 0 2 0 0 0 0 0 0 2 0 1 2 1 1 0 0 0 0 2 0\n",
      " 1 0 2 0 0 1 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 2 0 1 2 2 1 2 2 0 0 1 0 1 0\n",
      " 2 2 0 0 0 0 0 0 0 1 2 0 2 0 0 0 0 0 2 1 0 1 0 1 0 2 0 0 1 1 0 1 0 0 0 1 1\n",
      " 0 0 0 2 1 1 0 2 0 1 2 0 1 0 1 0 1 0 0 0 2 0 1 1 0 1 0 1 0 2 2 0 2 1 0 0 0\n",
      " 1 2 1 0 1 0 0 1 1 0 1 1 2 1 2 2 1 0 0 2 0 2 0 1 2 0 1 1 0 0 2 2 2 1 2 0 2\n",
      " 2 0 0 0 1 0 0 0 2 1 0 1 0 1 1 0 1 2 2 1 1 2 1 0 1]\n",
      "train accuracy :  0.9613095238095238\n",
      "test accuracy :  0.4027777777777778\n"
     ]
    }
   ],
   "source": [
    "# Predict test/train set\n",
    "W11 = params['W1']\n",
    "W22 = params['W2']\n",
    "b11= params['b']\n",
    "\n",
    "y_prediction_train = predict(W11,W22, b11, x_train)\n",
    "y_prediction_test = predict(W11,W22, b11, x_test)\n",
    "\n",
    "print(y_prediction_train)\n",
    "print(y_prediction_test)\n",
    "\n",
    "# Print train/test Errors\n",
    "print(\"train accuracy : \", metrics.accuracy_score(y_prediction_train, y_train_orig))\n",
    "print(\"test accuracy : \", metrics.accuracy_score(y_prediction_test, y_test_orig))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
