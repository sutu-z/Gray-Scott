{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Single-layer Neural Network with Pattern images based on Lengyel-Epstein modelÂ¶\n",
    "- X : imges, Z = W1 * gradient(X) + W2 * (X-X^3) + b\n",
    "- optimizer : Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import math\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset(144)\n",
    "x_orig = []\n",
    "y_orig = np.zeros((1,48))\n",
    "for i in range(1,145):\n",
    "    if i <= 48 :\n",
    "        folder = 0\n",
    "    elif i <=96 :\n",
    "        folder = 1\n",
    "    else:\n",
    "        folder = 2\n",
    "\n",
    "    img = Image.open('144/{0}/pattern_{1}.jpg'.format(folder,i)) \n",
    "    data = np.array(img)\n",
    "    x_orig.append(data)\n",
    "\n",
    "for i in range(1,3):\n",
    "    y_orig = np.append(y_orig, np.full((1, 48),i), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset(360)\n",
    "x_orig = []\n",
    "y_orig = np.zeros((1,120))\n",
    "for i in range(1,361):\n",
    "    if i <= 120 :\n",
    "        folder = 0\n",
    "    elif i <=240 :\n",
    "        folder = 1\n",
    "    else:\n",
    "        folder = 2\n",
    "\n",
    "    img = Image.open('360/{0}/pattern_{1}.jpg'.format(folder,i)) \n",
    "    data = np.array(img)\n",
    "    x_orig.append(data)\n",
    "\n",
    "for i in range(1,3):\n",
    "    y_orig = np.append(y_orig, np.full((1, 120),i), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset(720)\n",
    "x_orig = []\n",
    "y_orig = np.zeros((1,240))\n",
    "for i in range(1,721):\n",
    "    if i <= 240 :\n",
    "        folder = 0\n",
    "    elif i <=480 :\n",
    "        folder = 1\n",
    "    else:\n",
    "        folder = 2\n",
    "\n",
    "    img = Image.open('720/{0}/pattern_{1}.jpg'.format(folder,i)) \n",
    "    data = np.array(img)\n",
    "    x_orig.append(data)\n",
    "\n",
    "for i in range(1,3):\n",
    "    y_orig = np.append(y_orig, np.full((1, 240),i), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 64, 64)\n",
      "(1, 360)\n"
     ]
    }
   ],
   "source": [
    "# Explore dataset\n",
    "x_orig = np.array(x_orig)\n",
    "print(x_orig.shape)\n",
    "print(y_orig.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 64, 64)\n",
      "(1, 360)\n"
     ]
    }
   ],
   "source": [
    "# Random shuffle\n",
    "s = np.arange(x_orig.shape[0])\n",
    "np.random.shuffle(s)\n",
    "\n",
    "x_shuffle = x_orig[s,:]\n",
    "y_shuffle = y_orig[:,s]\n",
    "\n",
    "print(x_shuffle.shape)\n",
    "print(y_shuffle.shape)\n",
    "# y_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test datasets\n",
    "x_train_orig, x_test_orig, y_train_orig, y_test_orig = train_test_split(x_shuffle,y_shuffle.T, \n",
    "                                                                        test_size=0.3,  shuffle=True, random_state=1050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 64, 64)\n",
      "(252, 1)\n",
      "[87]\n",
      "[84]\n",
      "[81]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_orig.shape)\n",
    "print (y_train_orig.shape)\n",
    "print(sum(y_train_orig==0))\n",
    "print(sum(y_train_orig==1))\n",
    "print(sum(y_train_orig==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 252\n",
      "number of test examples = 108\n",
      "x_train shape: (4096, 252)\n",
      "y_train shape: (3, 252)\n",
      "x_test shape: (4096, 108)\n",
      "y_test shape: (3, 108)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Flatten the training and test images\n",
    "x_train_flatten = x_train_orig.reshape(x_train_orig.shape[0], -1).T\n",
    "x_test_flatten = x_test_orig.reshape(x_test_orig.shape[0], -1).T\n",
    "\n",
    "# Normalize image vectors\n",
    "x_train = (2/255)*x_train_flatten - 1\n",
    "x_test = (2/255)*x_test_flatten - 1\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "enc = OneHotEncoder()\n",
    "y1 = y_train_orig.reshape(-1,1)\n",
    "enc.fit(y1)\n",
    "y_train = enc.transform(y1).toarray()\n",
    "y_train = y_train.T\n",
    "\n",
    "y2 = y_test_orig.reshape(-1,1)\n",
    "enc.fit(y2)\n",
    "y_test = enc.transform(y2).toarray()\n",
    "y_test = y_test.T\n",
    "\n",
    "# Explore dataset \n",
    "print (\"number of training examples = \" + str(x_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(x_test.shape[1]))\n",
    "print (\"x_train shape: \" + str(x_train.shape))\n",
    "print (\"y_train shape: \" + str(y_train.shape))\n",
    "print (\"x_test shape: \" + str(x_test.shape))\n",
    "print (\"y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Define required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(nx, ny):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "        nx -- size of the input layer (4096)\n",
    "        ny -- size of the output layer (3)\n",
    "    \n",
    "    Returns:\n",
    "        W -- weight matrix of shape (ny, nx)\n",
    "        b -- bias vector of shape (ny, 1)\n",
    "\n",
    "    \"\"\"   \n",
    "    np.random.seed(1)\n",
    "\n",
    "    W1 = np.random.randn(ny,nx)*0.01\n",
    "    W2 = np.random.randn(ny,nx)*0.01\n",
    "    b = np.zeros((ny,1))\n",
    "\n",
    "    assert(W1.shape == (ny, nx))\n",
    "    assert(W2.shape == (ny, nx))\n",
    "    assert(b.shape == (ny, 1))\n",
    "\n",
    "    \n",
    "    return W1,W2, b  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    # compute the softmax activation\n",
    "    \n",
    "    S = np.exp(Z + np.max(Z)) / np.sum(np.exp(Z + np.max(Z)), axis = 0)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classlabel(Z):\n",
    "    # probabilities back into class labels\n",
    "    y_hat = Z.argmax(axis=0)\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_vec(X):\n",
    "    g_X_r = np.gradient(X, axis = 1)\n",
    "    g_X_c = np.gradient(X, axis = 0)\n",
    "    g_X = g_X_r**2 + g_X_c**2\n",
    "    return g_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(W1,W2, b, X, Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "#     n = Y.shape[0]\n",
    "    \n",
    "    # Forward Propagation\n",
    "    Z = np.dot(W1, gradient_vec(X))+ np.dot(W2, X-X**3) + b\n",
    "    A = softmax(Z)     # compute activation\n",
    "    \n",
    "    cost = (-1/m) * np.sum(Y * np.log(A))  # compute cost (Cross_entropy)\n",
    "     \n",
    "    # Backward propagation   \n",
    "    dW1 = (1/m) * (np.dot(gradient_vec(X),(A-Y).T)).T\n",
    "    dW2 = (1/m) * (np.dot(X-X**3, (A-Y).T).T)\n",
    "    db = (1/m) * (np.sum(A-Y))\n",
    "    \n",
    "#     assert(dW.shape == W.shape)\n",
    "#     assert(db.dtype == float)\n",
    "#     cost = np.squeeze(cost)\n",
    "#     assert(cost.shape == (Y.shape[0],1))\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"dW2\": dW2, \n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Single-2weight(X-X^3) Layer Neural Network with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X, Y, num_iterations, learning_rate, t, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, print_cost = False):\n",
    "\n",
    "    costs = []\n",
    "    W1, W2, b = initialize_parameters(4096,3)\n",
    "     # initialize with adam\n",
    "    v_dW1 = np.zeros((W1.shape[0],W1.shape[1]))\n",
    "    v_dW2 = np.zeros((W2.shape[0],W2.shape[1]))\n",
    "    v_db = np.zeros((b.shape[0],b.shape[1]))\n",
    "    \n",
    "    s_dW1 = np.zeros((W1.shape[0],W1.shape[1]))\n",
    "    s_dW2 = np.zeros((W2.shape[0],W2.shape[1]))\n",
    "    s_db = np.zeros((b.shape[0],b.shape[1]))\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        t+=1\n",
    "        grads, cost = propagate(W1,W2, b, X, Y)\n",
    "\n",
    "        dW1 = grads[\"dW1\"]\n",
    "        dW2 = grads[\"dW2\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update parameters with adam\n",
    "        v_dW1 = beta1 * v_dW1 + (1-beta1) * dW1\n",
    "        v_dW2 = beta1 * v_dW2 + (1-beta1) * dW2\n",
    "        v_db = beta1 * v_db + (1-beta1) * db\n",
    "\n",
    "        # Compute bias-corrected first moment estimate\n",
    "        v_corrected_dW1 = v_dW1 / (1-beta1**t)\n",
    "        v_corrected_dW2 = v_dW2 / (1-beta1**t)\n",
    "        v_corrected_db = v_db / (1-beta1**t)\n",
    "        \n",
    "        # Moving average of the squared gradients\n",
    "        s_dW1 = beta2 * s_dW1 + (1-beta2) * dW1 ** 2\n",
    "        s_dW2 = beta2 * s_dW2 + (1-beta2) * dW2 ** 2\n",
    "        s_db = beta2 * s_db + (1-beta2) * db ** 2\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate.\n",
    "        s_corrected_dW1 = s_dW1 / (1-beta2**t)\n",
    "        s_corrected_dW2 = s_dW2 / (1-beta2**t)\n",
    "        s_corrected_db = s_db / (1-beta2**t)\n",
    "\n",
    "        # Update parameters\n",
    "        W1 = W1 - (learning_rate) * ((v_corrected_dW1) / (s_corrected_dW1 **(1/2) + epsilon))\n",
    "        W2 = W2 - (learning_rate) * ((v_corrected_dW2) / (s_corrected_dW2 **(1/2) + epsilon))\n",
    "        b = b - (learning_rate) * ((v_corrected_db) / (s_corrected_db ** (1/2) + epsilon))\n",
    "\n",
    "        # Record the costs for plotting\n",
    "        if i % 10 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 10 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per 200)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    # Lets save the trainded parameters in a variable\n",
    "    params = {\"W1\": W1,\n",
    "              \"W2\": W2,\n",
    "              \"b\": b}    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"dW2\":dW2,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.104420\n",
      "Cost after iteration 10: 0.070933\n",
      "Cost after iteration 20: 0.002065\n",
      "Cost after iteration 30: 0.000670\n",
      "Cost after iteration 40: 0.000217\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-0.07677255 -0.08937745 -0.09896243 ... -0.2640534  -0.24455783\n",
      "  -0.21187225]\n",
      " [ 0.01217656 -0.03088971 -0.09840692 ...  0.05171841  0.10334786\n",
      "   0.08572131]\n",
      " [ 0.12526337  0.1984458   0.21882368 ...  0.20412094  0.19119018\n",
      "   0.19550691]]\n",
      "W2 = [[ 0.32272024  0.2473249   0.22240462 ...  0.12105156  0.17054457\n",
      "   0.17708555]\n",
      " [ 0.03793365  0.00407963 -0.05667789 ...  0.19039017  0.14637078\n",
      "   0.14096465]\n",
      " [-0.39441356 -0.34325961 -0.32510328 ... -0.34999924 -0.35534145\n",
      "  -0.34686062]]\n",
      "b = [[-2.63103325e-10]\n",
      " [-2.63103325e-10]\n",
      " [-2.63103325e-10]]\n"
     ]
    }
   ],
   "source": [
    "params, grads, costs = optimize(x_train, y_train, num_iterations=50, learning_rate=0.04,\n",
    "                                t=2, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, print_cost = True)\n",
    "\n",
    "print (\"W1 = \" + str(params[\"W1\"]))\n",
    "print (\"W2 = \" + str(params[\"W2\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W1, W2, b, X) :\n",
    "\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Compute \"A\" predicting the probabilities\n",
    "    Z = np.dot(W1, gradient_vec(X))+ np.dot(W2, X-X**3) + b\n",
    "    A = softmax(Z) \n",
    "\n",
    "    # Convert probabilities A to actual predictions\n",
    "    y_prediction = A.argmax(axis=0)\n",
    "    \n",
    "#     assert(y_prediction.shape == (1, m))\n",
    "    \n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 1 0 2 0 2 1 0 2 1 0 0 1 2 2 1 0 2 2 0 2 2 0 0 0 1 0 1 1 2 0 2 0 0\n",
      " 2 0 0 0 0 0 2 2 0 1 1 2 2 1 2 0 0 1 0 0 2 0 2 1 2 0 0 1 2 2 0 0 2 1 2 1 2\n",
      " 0 0 0 0 0 0 1 2 2 0 0 1 0 1 0 2 2 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 0 1 1 1 1 0 2 0 1 0 0 1 2 2 0 1 1 0 0 1 2 2 0 1 0 2 0 0 2 1 1 2 0 1 2 2\n",
      " 0 0 1 0 2 2 1 0 2 2 1 2 2 0 1 1 1 2 2 0 2 1 1 0 2 1 0 1 2 0 2 0 2 0 0 2 1\n",
      " 2 1 2 0 0 1 0 1 1 1 0 1 1 0 2 0 1 2 0 1 2 0 1 2 2 2 0 0 1 1 2 1 2 0 2 2 2\n",
      " 1 0 1 1 1 1 2 2 1 0 0 2 0 1 0 0 2 2 0 2 2 1 2 2 2 1 2 1 1 0]\n",
      "[2 0 1 1 1 2 2 0 1 2 2 1 2 1 1 0 1 1 2 0 1 1 0 0 2 0 0 1 0 1 2 0 0 2 0 1 2\n",
      " 0 1 2 0 1 0 0 0 1 2 1 1 0 1 0 2 0 1 2 1 2 0 0 0 1 2 2 2 1 0 0 0 2 1 2 2 0\n",
      " 0 2 1 0 1 1 1 2 2 1 2 1 2 0 0 2 1 2 1 2 1 1 2 1 2 0 2 0 0 2 0 1 0 2]\n",
      "train accuracy :  1.0\n",
      "test accuracy :  0.8981481481481481\n"
     ]
    }
   ],
   "source": [
    "# Predict test/train set\n",
    "W11 = params['W1']\n",
    "W22 = params['W2']\n",
    "b11= params['b']\n",
    "\n",
    "y_prediction_train = predict(W11,W22, b11, x_train)\n",
    "y_prediction_test = predict(W11,W22, b11, x_test)\n",
    "\n",
    "print(y_prediction_train)\n",
    "print(y_prediction_test)\n",
    "\n",
    "# Print train/test Errors\n",
    "print(\"train accuracy : \", metrics.accuracy_score(y_prediction_train, y_train_orig))\n",
    "print(\"test accuracy : \", metrics.accuracy_score(y_prediction_test, y_test_orig))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
